{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 7533.78 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 1591.99 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Test Dataset Sample:\n",
      "{'text': ['def unveils latest tech product', 'abc reports strong financial results for q2', 'abc corp declares bankruptcy after revenue drop', 'abc corp secures debt financing for expansion', 'company xyz launches new esg initiatives'], 'labels': [5, 7, 0, 1, 2], 'input_ids': [[0, 9232, 36685, 5290, 665, 2903, 1152, 2, 1, 1, 1, 1], [0, 36822, 690, 670, 613, 775, 13, 2231, 176, 2, 1, 1], [0, 36822, 44086, 26460, 7388, 71, 903, 1874, 2, 1, 1, 1], [0, 36822, 44086, 15636, 4123, 1126, 5200, 13, 2919, 2, 1, 1], [0, 24233, 3023, 42006, 10158, 92, 2714, 571, 5287, 2, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]}\n",
      "Tokenized Train Dataset Sample:\n",
      "{'text': ['xyz ltd declares bankruptcy amidst financial turmoil', 'def inc. secures $30 million loan from bank', 'abc and xyz form strategic alliance', 'abc corp reports record earnings for q1', 'abc corp issues new shares to raise capital'], 'labels': [0, 1, 4, 7, 3], 'input_ids': [[0, 32027, 329, 784, 26767, 26460, 7388, 24018, 613, 12225, 2, 1, 1, 1, 1], [0, 9232, 5853, 4, 15636, 4123, 68, 541, 153, 2541, 31, 827, 2, 1, 1], [0, 36822, 8, 3023, 42006, 1026, 3461, 6529, 2, 1, 1, 1, 1, 1, 1], [0, 36822, 44086, 690, 638, 1107, 13, 2231, 134, 2, 1, 1, 1, 1, 1], [0, 36822, 44086, 743, 92, 327, 7, 1693, 812, 2, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]}\n",
      "Formatted Train Dataset Sample:\n",
      "Dataset({\n",
      "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 30\n",
      "})\n",
      "Formatted Test Dataset Sample:\n",
      "Dataset({\n",
      "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 8\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at MoritzLaurer/roberta-large-zeroshot-v2.0-c and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([2, 1024]) in the checkpoint and torch.Size([8, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\admin\\Desktop\\traini\\autotrain-env\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\Desktop\\traini\\autotrain-env\\Lib\\site-packages\\transformers\\training_args.py:1489: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "  3%|â–Ž         | 4/120 [00:07<03:18,  1.71s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                               \n",
      "  3%|â–Ž         | 4/120 [00:07<03:18,  1.71s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1254987716674805, 'eval_runtime': 0.1965, 'eval_samples_per_second': 40.711, 'eval_steps_per_second': 5.089, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 8/120 [00:15<03:38,  1.95s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                               \n",
      "  7%|â–‹         | 8/120 [00:15<03:38,  1.95s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.072481632232666, 'eval_runtime': 0.2549, 'eval_samples_per_second': 31.38, 'eval_steps_per_second': 3.923, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 12/120 [00:23<03:50,  2.14s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 10%|â–ˆ         | 12/120 [00:24<03:50,  2.14s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0217044353485107, 'eval_runtime': 0.2571, 'eval_samples_per_second': 31.111, 'eval_steps_per_second': 3.889, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 16/120 [00:32<03:44,  2.16s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 13%|â–ˆâ–Ž        | 16/120 [00:33<03:44,  2.16s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0028555393218994, 'eval_runtime': 0.2676, 'eval_samples_per_second': 29.891, 'eval_steps_per_second': 3.736, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 20/120 [00:41<03:35,  2.16s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 17%|â–ˆâ–‹        | 20/120 [00:42<03:35,  2.16s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9656320810317993, 'eval_runtime': 0.2609, 'eval_samples_per_second': 30.669, 'eval_steps_per_second': 3.834, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 24/120 [00:50<03:28,  2.17s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 20%|â–ˆâ–ˆ        | 24/120 [00:50<03:28,  2.17s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9148555994033813, 'eval_runtime': 0.2712, 'eval_samples_per_second': 29.497, 'eval_steps_per_second': 3.687, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 28/120 [00:59<03:20,  2.18s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 23%|â–ˆâ–ˆâ–Ž       | 28/120 [00:59<03:20,  2.18s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8713290691375732, 'eval_runtime': 0.2602, 'eval_samples_per_second': 30.749, 'eval_steps_per_second': 3.844, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 32/120 [01:08<03:11,  2.18s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 27%|â–ˆâ–ˆâ–‹       | 32/120 [01:08<03:11,  2.18s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7546573877334595, 'eval_runtime': 0.2681, 'eval_samples_per_second': 29.839, 'eval_steps_per_second': 3.73, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 36/120 [01:17<03:02,  2.18s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 36/120 [01:17<03:02,  2.18s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6826660633087158, 'eval_runtime': 0.254, 'eval_samples_per_second': 31.5, 'eval_steps_per_second': 3.938, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 40/120 [01:26<02:53,  2.16s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 40/120 [01:26<02:53,  2.16s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5735118389129639, 'eval_runtime': 0.2629, 'eval_samples_per_second': 30.435, 'eval_steps_per_second': 3.804, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 44/120 [01:35<02:45,  2.18s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 44/120 [01:35<02:45,  2.18s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4754071235656738, 'eval_runtime': 0.2676, 'eval_samples_per_second': 29.901, 'eval_steps_per_second': 3.738, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 48/120 [01:44<02:38,  2.20s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 48/120 [01:44<02:38,  2.20s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4091920852661133, 'eval_runtime': 0.2645, 'eval_samples_per_second': 30.242, 'eval_steps_per_second': 3.78, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 52/120 [01:53<02:30,  2.21s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 52/120 [01:53<02:30,  2.21s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3501088619232178, 'eval_runtime': 0.2624, 'eval_samples_per_second': 30.482, 'eval_steps_per_second': 3.81, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 56/120 [02:02<02:19,  2.19s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 56/120 [02:02<02:19,  2.19s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.317955732345581, 'eval_runtime': 0.2653, 'eval_samples_per_second': 30.152, 'eval_steps_per_second': 3.769, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 60/120 [02:11<02:11,  2.19s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 60/120 [02:11<02:11,  2.19s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2650952339172363, 'eval_runtime': 0.2627, 'eval_samples_per_second': 30.455, 'eval_steps_per_second': 3.807, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 64/120 [02:20<02:02,  2.18s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 64/120 [02:20<02:02,  2.18s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1375560760498047, 'eval_runtime': 0.2708, 'eval_samples_per_second': 29.538, 'eval_steps_per_second': 3.692, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 68/120 [02:29<01:53,  2.19s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 68/120 [02:29<01:53,  2.19s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0662130117416382, 'eval_runtime': 0.2753, 'eval_samples_per_second': 29.059, 'eval_steps_per_second': 3.632, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 72/120 [02:38<01:45,  2.20s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 72/120 [02:38<01:45,  2.20s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.008046269416809, 'eval_runtime': 0.2617, 'eval_samples_per_second': 30.57, 'eval_steps_per_second': 3.821, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 76/120 [02:47<01:36,  2.20s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 76/120 [02:48<01:36,  2.20s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9565284848213196, 'eval_runtime': 0.2642, 'eval_samples_per_second': 30.279, 'eval_steps_per_second': 3.785, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 80/120 [02:56<01:27,  2.19s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 80/120 [02:57<01:27,  2.19s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9272826313972473, 'eval_runtime': 0.2663, 'eval_samples_per_second': 30.037, 'eval_steps_per_second': 3.755, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 84/120 [03:05<01:19,  2.21s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 84/120 [03:06<01:19,  2.21s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9141188859939575, 'eval_runtime': 0.2775, 'eval_samples_per_second': 28.831, 'eval_steps_per_second': 3.604, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 88/120 [03:15<01:13,  2.30s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 88/120 [03:15<01:13,  2.30s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8514343500137329, 'eval_runtime': 0.2843, 'eval_samples_per_second': 28.141, 'eval_steps_per_second': 3.518, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 92/120 [03:24<01:02,  2.22s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 92/120 [03:24<01:02,  2.22s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7918561697006226, 'eval_runtime': 0.2933, 'eval_samples_per_second': 27.277, 'eval_steps_per_second': 3.41, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 96/120 [03:33<00:53,  2.21s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 96/120 [03:33<00:53,  2.21s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7495076656341553, 'eval_runtime': 0.2608, 'eval_samples_per_second': 30.675, 'eval_steps_per_second': 3.834, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 100/120 [03:42<00:44,  2.20s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 100/120 [03:43<00:44,  2.20s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.724989652633667, 'eval_runtime': 0.2624, 'eval_samples_per_second': 30.484, 'eval_steps_per_second': 3.811, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 104/120 [03:51<00:35,  2.20s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 104/120 [03:52<00:35,  2.20s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.708335816860199, 'eval_runtime': 0.2742, 'eval_samples_per_second': 29.178, 'eval_steps_per_second': 3.647, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 108/120 [04:00<00:26,  2.20s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 108/120 [04:01<00:26,  2.20s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6902002692222595, 'eval_runtime': 0.2678, 'eval_samples_per_second': 29.871, 'eval_steps_per_second': 3.734, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 112/120 [04:09<00:17,  2.22s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 112/120 [04:10<00:17,  2.22s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6742333173751831, 'eval_runtime': 0.2633, 'eval_samples_per_second': 30.38, 'eval_steps_per_second': 3.798, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 116/120 [04:19<00:08,  2.21s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 116/120 [04:19<00:08,  2.21s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6637663245201111, 'eval_runtime': 0.3298, 'eval_samples_per_second': 24.257, 'eval_steps_per_second': 3.032, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [04:28<00:00,  2.20s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [04:28<00:00,  2.20s/it]\n",
      "\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [04:28<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6590226888656616, 'eval_runtime': 0.2561, 'eval_samples_per_second': 31.232, 'eval_steps_per_second': 3.904, 'epoch': 30.0}\n",
      "{'train_runtime': 268.4704, 'train_samples_per_second': 3.352, 'train_steps_per_second': 0.447, 'train_loss': 1.2363861083984375, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1003.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.6590226888656616, 'eval_runtime': 0.2647, 'eval_samples_per_second': 30.226, 'eval_steps_per_second': 3.778, 'epoch': 30.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./saved_model\\\\tokenizer_config.json',\n",
       " './saved_model\\\\special_tokens_map.json',\n",
       " './saved_model\\\\vocab.json',\n",
       " './saved_model\\\\merges.txt',\n",
       " './saved_model\\\\added_tokens.json',\n",
       " './saved_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Ensure GPU is visible\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA is available\" if torch.cuda.is_available() else \"CUDA is not available\")\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(r'C:\\Users\\admin\\Desktop\\SQ\\try.csv')\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess_text(text):\n",
    "    return text.lower().replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "# Apply preprocessing\n",
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['target'] = label_encoder.fit_transform(data['target'])\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "# Split the dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['target'], random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_data.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_data.reset_index(drop=True))\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/roberta-large-zeroshot-v2.0-c\")\n",
    "\n",
    "# Tokenize the texts\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Rename the target column to labels\n",
    "train_dataset = train_dataset.rename_column(\"target\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"target\", \"labels\")\n",
    "\n",
    "# Print the tokenized datasets to check\n",
    "print(\"Tokenized Test Dataset Sample:\")\n",
    "print(test_dataset[:5])\n",
    "print(\"Tokenized Train Dataset Sample:\")\n",
    "print(train_dataset[:5])\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Print the formatted datasets to verify\n",
    "print(\"Formatted Train Dataset Sample:\")\n",
    "print(train_dataset)\n",
    "print(\"Formatted Test Dataset Sample:\")\n",
    "print(test_dataset)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"MoritzLaurer/roberta-large-zeroshot-v2.0-c\", num_labels=num_labels, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./saved_model',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30,\n",
    "    no_cuda=not torch.cuda.is_available(),  # Use CUDA if available\n",
    "    report_to=[]  \n",
    ")\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {results}\")\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model('./saved_model')\n",
    "\n",
    "# Optionally, save the tokenizer as well\n",
    "tokenizer.save_pretrained('./saved_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 5524.94 examples/s]\n",
      "c:\\Users\\admin\\Desktop\\traini\\autotrain-env\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\Desktop\\traini\\autotrain-env\\Lib\\site-packages\\transformers\\training_args.py:1489: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49643397331237793, 'eval_accuracy': 1.0, 'eval_runtime': 2.869, 'eval_samples_per_second': 6.622, 'eval_steps_per_second': 1.046}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, load_metric\n",
    "\n",
    "# Ensure GPU is visible\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Load your test dataset\n",
    "data = pd.read_csv(r'C:\\Users\\admin\\Desktop\\SQ\\try.csv')\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess_text(text):\n",
    "    return text.lower().replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "# Apply preprocessing\n",
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['target'] = label_encoder.fit_transform(data['target'])\n",
    "\n",
    "# Split the dataset\n",
    "_, test_data = train_test_split(data, test_size=0.5, stratify=data['target'], random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "test_dataset = Dataset.from_pandas(test_data.reset_index(drop=True))\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model_path = './saved_model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(r\"C:\\Users\\admin\\Desktop\\traini\\saved_model\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(r\"C:\\Users\\admin\\Desktop\\traini\\saved_model\")\n",
    "\n",
    "# Tokenize the texts\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Rename the target column to labels\n",
    "test_dataset = test_dataset.rename_column(\"target\", \"labels\")\n",
    "\n",
    "# Set format for PyTorch\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Define the compute_metrics function\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = torch.tensor(predictions)  # Convert predictions to tensor\n",
    "    predictions = torch.argmax(predictions, dim=1)\n",
    "    return metric.compute(predictions=predictions, references=torch.tensor(labels))\n",
    "\n",
    "# Define evaluation arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_eval_batch_size=8,\n",
    "    no_cuda=True,\n",
    "    report_to=[]  # Disabling all reporting integrations including codecarbon\n",
    ")\n",
    "\n",
    "# Create a Trainer instance for evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autotrain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
